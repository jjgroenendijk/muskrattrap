<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.14.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>IoT-muskrattrap: serverSide/nodered/node_modules/lru-cache Directory Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">IoT-muskrattrap
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.14.0 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search/",'.html');
</script>
<script type="text/javascript">
$(function() { codefold.init(); });
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(function(){initNavTree('dir_05a0747f27b3c00a8b909fc81cc1a3d1.html','',''); });
</script>
<div id="container">
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">lru-cache Directory Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Directory dependency graph for lru-cache:</div>
<div class="dyncontent">
<div class="center"><img src="dir_05a0747f27b3c00a8b909fc81cc1a3d1_dep.png" border="0" usemap="#adir__05a0747f27b3c00a8b909fc81cc1a3d1__dep" loading="lazy" alt="serverSide/nodered/node_modules/lru-cache"/></div>
<map name="adir__05a0747f27b3c00a8b909fc81cc1a3d1__dep" id="adir__05a0747f27b3c00a8b909fc81cc1a3d1__dep">
<area shape="rect" href="dir_05a0747f27b3c00a8b909fc81cc1a3d1.html" title="lru&#45;cache" alt="" coords="31,52,105,78"/>
<area shape="rect" href="dir_1fe2c0d618eaa8bd2b6d3d78892e74a8.html" title="node_modules" alt="" coords="16,16,121,89"/>
</map>
</div>
<a name="details" id="details"></a><h2 id="header-details" class="groupheader">Detailed Description</h2>
<h1 class="doxsection"><a class="anchor" id="autotoc_md952"></a>
lru-cache</h1>
<p>A cache object that deletes the least-recently-used items.</p>
<p>Specify a max number of the most recently used items that you want to keep, and this cache will keep that many of the most recently accessed items.</p>
<p>This is not primarily a TTL cache, and does not make strong TTL guarantees. There is no preemptive pruning of expired items by default, but you <em>may</em> set a TTL on the cache or on a single <span class="tt">set</span>. If you do so, it will treat expired items as missing, and delete them when fetched. If you are more interested in TTL caching than LRU caching, check out <a href="http://npm.im/@isaacs/ttlcache">@isaacs/ttlcache</a>.</p>
<p>As of version 7, this is one of the most performant LRU implementations available in JavaScript, and supports a wide diversity of use cases. However, note that using some of the features will necessarily impact performance, by causing the cache to have to do more work. See the "Performance" section below.</p>
<h1 class="doxsection"><a class="anchor" id="autotoc_md953"></a>
Installation</h1>
<div class="fragment"><div class="line">npm install lru-cache --save</div>
</div><!-- fragment --><h1 class="doxsection"><a class="anchor" id="autotoc_md954"></a>
Usage</h1>
<div class="fragment"><div class="line">// hybrid module, either works</div>
<div class="line">import LRUCache from &#39;lru-cache&#39;</div>
<div class="line">// or:</div>
<div class="line">const LRUCache = require(&#39;lru-cache&#39;)</div>
<div class="line"> </div>
<div class="line">// At least one of &#39;max&#39;, &#39;ttl&#39;, or &#39;maxSize&#39; is required, to prevent</div>
<div class="line">// unsafe unbounded storage.</div>
<div class="line">//</div>
<div class="line">// In most cases, it&#39;s best to specify a max for performance, so all</div>
<div class="line">// the required memory allocation is done up-front.</div>
<div class="line">//</div>
<div class="line">// All the other options are optional, see the sections below for</div>
<div class="line">// documentation on what each one does.  Most of them can be</div>
<div class="line">// overridden for specific items in get()/set()</div>
<div class="line">const options = {</div>
<div class="line">  max: 500,</div>
<div class="line"> </div>
<div class="line">  // for use with tracking overall storage size</div>
<div class="line">  maxSize: 5000,</div>
<div class="line">  sizeCalculation: (value, key) =&gt; {</div>
<div class="line">    return 1</div>
<div class="line">  },</div>
<div class="line"> </div>
<div class="line">  // for use when you need to clean up something when objects</div>
<div class="line">  // are evicted from the cache</div>
<div class="line">  dispose: (value, key) =&gt; {</div>
<div class="line">    freeFromMemoryOrWhatever(value)</div>
<div class="line">  },</div>
<div class="line"> </div>
<div class="line">  // how long to live in ms</div>
<div class="line">  ttl: 1000 * 60 * 5,</div>
<div class="line"> </div>
<div class="line">  // return stale items before removing from cache?</div>
<div class="line">  allowStale: false,</div>
<div class="line"> </div>
<div class="line">  updateAgeOnGet: false,</div>
<div class="line">  updateAgeOnHas: false,</div>
<div class="line"> </div>
<div class="line">  // async method to use for cache.fetch(), for</div>
<div class="line">  // stale-while-revalidate type of behavior</div>
<div class="line">  fetchMethod: async (key, staleValue, { options, signal }) =&gt; {},</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">const cache = new LRUCache(options)</div>
<div class="line"> </div>
<div class="line">cache.set(&#39;key&#39;, &#39;value&#39;)</div>
<div class="line">cache.get(&#39;key&#39;) // &quot;value&quot;</div>
<div class="line"> </div>
<div class="line">// non-string keys ARE fully supported</div>
<div class="line">// but note that it must be THE SAME object, not</div>
<div class="line">// just a JSON-equivalent object.</div>
<div class="line">var someObject = { a: 1 }</div>
<div class="line">cache.set(someObject, &#39;a value&#39;)</div>
<div class="line">// Object keys are not toString()-ed</div>
<div class="line">cache.set(&#39;[object Object]&#39;, &#39;a different value&#39;)</div>
<div class="line">assert.equal(cache.get(someObject), &#39;a value&#39;)</div>
<div class="line">// A similar object with same keys/values won&#39;t work,</div>
<div class="line">// because it&#39;s a different object identity</div>
<div class="line">assert.equal(cache.get({ a: 1 }), undefined)</div>
<div class="line"> </div>
<div class="line">cache.clear() // empty the cache</div>
</div><!-- fragment --><p>If you put more stuff in it, then items will fall out.</p>
<h1 class="doxsection"><a class="anchor" id="autotoc_md955"></a>
Options</h1>
<h2 class="doxsection"><a class="anchor" id="autotoc_md956"></a>
<span class="tt">max</span></h2>
<p>The maximum number of items that remain in the cache (assuming no TTL pruning or explicit deletions). Note that fewer items may be stored if size calculation is used, and <span class="tt">maxSize</span> is exceeded. This must be a positive finite intger.</p>
<p>At least one of <span class="tt">max</span>, <span class="tt">maxSize</span>, or <span class="tt">TTL</span> is required. This must be a positive integer if set.</p>
<p><b>It is strongly recommended to set a <span class="tt">max</span> to prevent unbounded growth of the cache.</b> See "Storage Bounds Safety" below.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md957"></a>
<span class="tt">maxSize</span></h2>
<p>Set to a positive integer to track the sizes of items added to the cache, and automatically evict items in order to stay below this size. Note that this may result in fewer than <span class="tt">max</span> items being stored.</p>
<p>Attempting to add an item to the cache whose calculated size is greater that this amount will be a no-op. The item will not be cached, and no other items will be evicted.</p>
<p>Optional, must be a positive integer if provided.</p>
<p>Sets <span class="tt">maxEntrySize</span> to the same value, unless a different value is provided for <span class="tt">maxEntrySize</span>.</p>
<p>At least one of <span class="tt">max</span>, <span class="tt">maxSize</span>, or <span class="tt">TTL</span> is required. This must be a positive integer if set.</p>
<p>Even if size tracking is enabled, <b>it is strongly recommended to set a <span class="tt">max</span> to prevent unbounded growth of the cache.</b> See "Storage Bounds Safety" below.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md958"></a>
<span class="tt">maxEntrySize</span></h2>
<p>Set to a positive integer to track the sizes of items added to the cache, and prevent caching any item over a given size. Attempting to add an item whose calculated size is greater than this amount will be a no-op. The item will not be cached, and no other items will be evicted.</p>
<p>Optional, must be a positive integer if provided. Defaults to the value of <span class="tt">maxSize</span> if provided.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md959"></a>
<span class="tt">sizeCalculation</span></h2>
<p>Function used to calculate the size of stored items. If you're storing strings or buffers, then you probably want to do something like <span class="tt">n =&gt; n.length</span>. The item is passed as the first argument, and the key is passed as the second argument.</p>
<p>This may be overridden by passing an options object to <span class="tt">cache.set()</span>.</p>
<p>Requires <span class="tt">maxSize</span> to be set.</p>
<p>If the <span class="tt">size</span> (or return value of <span class="tt">sizeCalculation</span>) for a given entry is greater than <span class="tt">maxEntrySize</span>, then the item will not be added to the cache.</p>
<p>Deprecated alias: <span class="tt">length</span></p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md960"></a>
<span class="tt">fetchMethod</span></h2>
<p>Function that is used to make background asynchronous fetches. Called with <span class="tt">fetchMethod(key, staleValue, { signal, options,
context })</span>. May return a Promise.</p>
<p>If <span class="tt">fetchMethod</span> is not provided, then <span class="tt">cache.fetch(key)</span> is equivalent to <span class="tt">Promise.resolve(cache.get(key))</span>.</p>
<p>The <span class="tt">signal</span> object is an <span class="tt">AbortSignal</span> if that's available in the global object, otherwise it's a pretty close polyfill.</p>
<p>If at any time, <span class="tt">signal.aborted</span> is set to <span class="tt">true</span>, or if the <span class="tt">signal.onabort</span> method is called, or if it emits an &lsquo;'abort&rsquo;<span class="tt">
event which you can listen to with </span>addEventListener`, then that means that the fetch should be abandoned. This may be passed along to async functions aware of AbortController/AbortSignal behavior.</p>
<p>The <span class="tt">fetchMethod</span> should <b>only</b> return <span class="tt">undefined</span> or a Promise resolving to <span class="tt">undefined</span> if the AbortController signaled an <span class="tt">abort</span> event. In all other cases, it should return or resolve to a value suitable for adding to the cache.</p>
<p>The <span class="tt">options</span> object is a union of the options that may be provided to <span class="tt">set()</span> and <span class="tt">get()</span>. If they are modified, then that will result in modifying the settings to <span class="tt">cache.set()</span> when the value is resolved, and in the case of <span class="tt">noDeleteOnFetchRejection</span> and <span class="tt">allowStaleOnFetchRejection</span>, the handling of <span class="tt">fetchMethod</span> failures.</p>
<p>For example, a DNS cache may update the TTL based on the value returned from a remote DNS server by changing <span class="tt">options.ttl</span> in the <span class="tt">fetchMethod</span>.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md961"></a>
<span class="tt">fetchContext</span></h2>
<p>Arbitrary data that can be passed to the <span class="tt">fetchMethod</span> as the <span class="tt">context</span> option.</p>
<p>Note that this will only be relevant when the <span class="tt">cache.fetch()</span> call needs to call <span class="tt">fetchMethod()</span>. Thus, any data which will meaningfully vary the fetch response needs to be present in the key. This is primarily intended for including <span class="tt">x-request-id</span> headers and the like for debugging purposes, which do not affect the <span class="tt">fetchMethod()</span> response.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md962"></a>
<span class="tt">noDeleteOnFetchRejection</span></h2>
<p>If a <span class="tt">fetchMethod</span> throws an error or returns a rejected promise, then by default, any existing stale value will be removed from the cache.</p>
<p>If <span class="tt">noDeleteOnFetchRejection</span> is set to <span class="tt">true</span>, then this behavior is suppressed, and the stale value remains in the cache in the case of a rejected <span class="tt">fetchMethod</span>.</p>
<p>This is important in cases where a <span class="tt">fetchMethod</span> is <em>only</em> called as a background update while the stale value is returned, when <span class="tt">allowStale</span> is used.</p>
<p>This is implicitly in effect when <span class="tt">allowStaleOnFetchRejection</span> is set.</p>
<p>This may be set in calls to <span class="tt">fetch()</span>, or defaulted on the constructor, or overridden by modifying the options object in the <span class="tt">fetchMethod</span>.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md963"></a>
<span class="tt">allowStaleOnFetchRejection</span></h2>
<p>Set to true to return a stale value from the cache when a <span class="tt">fetchMethod</span> throws an error or returns a rejected Promise.</p>
<p>If a <span class="tt">fetchMethod</span> fails, and there is no stale value available, the <span class="tt">fetch()</span> will resolve to <span class="tt">undefined</span>. Ie, all <span class="tt">fetchMethod</span> errors are suppressed.</p>
<p>Implies <span class="tt">noDeleteOnFetchRejection</span>.</p>
<p>This may be set in calls to <span class="tt">fetch()</span>, or defaulted on the constructor, or overridden by modifying the options object in the <span class="tt">fetchMethod</span>.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md964"></a>
<span class="tt">allowStaleOnFetchAbort</span></h2>
<p>Set to true to return a stale value from the cache when the <span class="tt">AbortSignal</span> passed to the <span class="tt">fetchMethod</span> dispatches an &lsquo;'abort&rsquo;` event, whether user-triggered, or due to internal cache behavior.</p>
<p>Unless <span class="tt">ignoreFetchAbort</span> is also set, the underlying <span class="tt">fetchMethod</span> will still be considered canceled, and its return value will be ignored and not cached.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md965"></a>
<span class="tt">ignoreFetchAbort</span></h2>
<p>Set to true to ignore the <span class="tt">abort</span> event emitted by the <span class="tt">AbortSignal</span> object passed to <span class="tt">fetchMethod</span>, and still cache the resulting resolution value, as long as it is not <span class="tt">undefined</span>.</p>
<p>When used on its own, this means aborted <span class="tt">fetch()</span> calls are not immediately resolved or rejected when they are aborted, and instead take the full time to await.</p>
<p>When used with <span class="tt">allowStaleOnFetchAbort</span>, aborted <span class="tt">fetch()</span> calls will resolve immediately to their stale cached value or <span class="tt">undefined</span>, and will continue to process and eventually update the cache when they resolve, as long as the resulting value is not <span class="tt">undefined</span>, thus supporting a "return stale on timeout while
refreshing" mechanism by passing <span class="tt">AbortSignal.timeout(n)</span> as the signal.</p>
<p>For example:</p>
<div class="fragment"><div class="line">const c = new LRUCache({</div>
<div class="line">  ttl: 100,</div>
<div class="line">  ignoreFetchAbort: true,</div>
<div class="line">  allowStaleOnFetchAbort: true,</div>
<div class="line">  fetchMethod: async (key, oldValue, { signal }) =&gt; {</div>
<div class="line">    // note: do NOT pass the signal to fetch()!</div>
<div class="line">    // let&#39;s say this fetch can take a long time.</div>
<div class="line">    const res = await fetch(`https://slow-backend-server/${key}`)</div>
<div class="line">    return await res.json()</div>
<div class="line">  },</div>
<div class="line">})</div>
<div class="line"> </div>
<div class="line">// this will return the stale value after 100ms, while still</div>
<div class="line">// updating in the background for next time.</div>
<div class="line">const val = await c.fetch(&#39;key&#39;, { signal: AbortSignal.timeout(100) })</div>
</div><!-- fragment --><p><b>Note</b>: regardless of this setting, an <span class="tt">abort</span> event <em>is still emitted on the <span class="tt">AbortSignal</span> object</em>, so may result in invalid results when passed to other underlying APIs that use AbortSignals.</p>
<p>This may be overridden on the <span class="tt">fetch()</span> call or in the <span class="tt">fetchMethod</span> itself.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md966"></a>
<span class="tt">dispose</span></h2>
<p>Function that is called on items when they are dropped from the cache, as <span class="tt">this.dispose(value, key, reason)</span>.</p>
<p>This can be handy if you want to close file descriptors or do other cleanup tasks when items are no longer stored in the cache.</p>
<p><b>NOTE</b>: It is called <em>before</em> the item has been fully removed from the cache, so if you want to put it right back in, you need to wait until the next tick. If you try to add it back in during the <span class="tt">dispose()</span> function call, it will break things in subtle and weird ways.</p>
<p>Unlike several other options, this may <em>not</em> be overridden by passing an option to <span class="tt">set()</span>, for performance reasons. If disposal functions may vary between cache entries, then the entire list must be scanned on every cache swap, even if no disposal function is in use.</p>
<p>The <span class="tt">reason</span> will be one of the following strings, corresponding to the reason for the item's deletion:</p>
<ul>
<li><span class="tt">evict</span> Item was evicted to make space for a new addition</li>
<li><span class="tt">set</span> Item was overwritten by a new value</li>
<li><span class="tt">delete</span> Item was removed by explicit <span class="tt">cache.delete(key)</span> or by calling <span class="tt">cache.clear()</span>, which deletes everything.</li>
</ul>
<p>The <span class="tt">dispose()</span> method is <em>not</em> called for canceled calls to <span class="tt">fetchMethod()</span>. If you wish to handle evictions, overwrites, and deletes of in-flight asynchronous fetches, you must use the <span class="tt">AbortSignal</span> provided.</p>
<p>Optional, must be a function.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md967"></a>
<span class="tt">disposeAfter</span></h2>
<p>The same as <span class="tt">dispose</span>, but called <em>after</em> the entry is completely removed and the cache is once again in a clean state.</p>
<p>It is safe to add an item right back into the cache at this point. However, note that it is <em>very</em> easy to inadvertently create infinite recursion in this way.</p>
<p>The <span class="tt">disposeAfter()</span> method is <em>not</em> called for canceled calls to <span class="tt">fetchMethod()</span>. If you wish to handle evictions, overwrites, and deletes of in-flight asynchronous fetches, you must use the <span class="tt">AbortSignal</span> provided.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md968"></a>
<span class="tt">noDisposeOnSet</span></h2>
<p>Set to <span class="tt">true</span> to suppress calling the <span class="tt">dispose()</span> function if the entry key is still accessible within the cache.</p>
<p>This may be overridden by passing an options object to <span class="tt">cache.set()</span>.</p>
<p>Boolean, default <span class="tt">false</span>. Only relevant if <span class="tt">dispose</span> or <span class="tt">disposeAfter</span> options are set.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md969"></a>
<span class="tt">ttl</span></h2>
<p>Max time to live for items before they are considered stale. Note that stale items are NOT preemptively removed by default, and MAY live in the cache, contributing to its LRU max, long after they have expired.</p>
<p>Also, as this cache is optimized for LRU/MRU operations, some of the staleness/TTL checks will reduce performance.</p>
<p>This is not primarily a TTL cache, and does not make strong TTL guarantees. There is no pre-emptive pruning of expired items, but you <em>may</em> set a TTL on the cache, and it will treat expired items as missing when they are fetched, and delete them.</p>
<p>Optional, but must be a positive integer in ms if specified.</p>
<p>This may be overridden by passing an options object to <span class="tt">cache.set()</span>.</p>
<p>At least one of <span class="tt">max</span>, <span class="tt">maxSize</span>, or <span class="tt">TTL</span> is required. This must be a positive integer if set.</p>
<p>Even if ttl tracking is enabled, <b>it is strongly recommended to set a <span class="tt">max</span> to prevent unbounded growth of the cache.</b> See "Storage Bounds Safety" below.</p>
<p>If ttl tracking is enabled, and <span class="tt">max</span> and <span class="tt">maxSize</span> are not set, and <span class="tt">ttlAutopurge</span> is not set, then a warning will be emitted cautioning about the potential for unbounded memory consumption.</p>
<p>Deprecated alias: <span class="tt">maxAge</span></p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md970"></a>
<span class="tt">noUpdateTTL</span></h2>
<p>Boolean flag to tell the cache to not update the TTL when setting a new value for an existing key (ie, when updating a value rather than inserting a new value). Note that the TTL value is <em>always</em> set (if provided) when adding a new entry into the cache.</p>
<p>This may be passed as an option to <span class="tt">cache.set()</span>.</p>
<p>Boolean, default false.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md971"></a>
<span class="tt">ttlResolution</span></h2>
<p>Minimum amount of time in ms in which to check for staleness. Defaults to <span class="tt">1</span>, which means that the current time is checked at most once per millisecond.</p>
<p>Set to <span class="tt">0</span> to check the current time every time staleness is tested.</p>
<p>Note that setting this to a higher value <em>will</em> improve performance somewhat while using ttl tracking, albeit at the expense of keeping stale items around a bit longer than intended.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md972"></a>
<span class="tt">ttlAutopurge</span></h2>
<p>Preemptively remove stale items from the cache.</p>
<p>Note that this may <em>significantly</em> degrade performance, especially if the cache is storing a large number of items. It is almost always best to just leave the stale items in the cache, and let them fall out as new items are added.</p>
<p>Note that this means that <span class="tt">allowStale</span> is a bit pointless, as stale items will be deleted almost as soon as they expire.</p>
<p>Use with caution!</p>
<p>Boolean, default <span class="tt">false</span></p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md973"></a>
<span class="tt">allowStale</span></h2>
<p>By default, if you set <span class="tt">ttl</span>, it'll only delete stale items from the cache when you <span class="tt">get(key)</span>. That is, it's not preemptively pruning items.</p>
<p>If you set <span class="tt">allowStale:true</span>, it'll return the stale value as well as deleting it. If you don't set this, then it'll return <span class="tt">undefined</span> when you try to get a stale entry.</p>
<p>Note that when a stale entry is fetched, <em>even if it is returned due to <span class="tt">allowStale</span> being set</em>, it is removed from the cache immediately. You can immediately put it back in the cache if you wish, thus resetting the TTL.</p>
<p>This may be overridden by passing an options object to <span class="tt">cache.get()</span>. The <span class="tt">cache.has()</span> method will always return <span class="tt">false</span> for stale items.</p>
<p>Boolean, default false, only relevant if <span class="tt">ttl</span> is set.</p>
<p>Deprecated alias: <span class="tt">stale</span></p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md974"></a>
<span class="tt">noDeleteOnStaleGet</span></h2>
<p>When using time-expiring entries with <span class="tt">ttl</span>, by default stale items will be removed from the cache when the key is accessed with <span class="tt">cache.get()</span>.</p>
<p>Setting <span class="tt">noDeleteOnStaleGet</span> to <span class="tt">true</span> will cause stale items to remain in the cache, until they are explicitly deleted with <span class="tt">cache.delete(key)</span>, or retrieved with <span class="tt">noDeleteOnStaleGet</span> set to <span class="tt">false</span>.</p>
<p>This may be overridden by passing an options object to <span class="tt">cache.get()</span>.</p>
<p>Boolean, default false, only relevant if <span class="tt">ttl</span> is set.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md975"></a>
<span class="tt">updateAgeOnGet</span></h2>
<p>When using time-expiring entries with <span class="tt">ttl</span>, setting this to <span class="tt">true</span> will make each item's age reset to 0 whenever it is retrieved from cache with <span class="tt">get()</span>, causing it to not expire. (It can still fall out of cache based on recency of use, of course.)</p>
<p>This may be overridden by passing an options object to <span class="tt">cache.get()</span>.</p>
<p>Boolean, default false, only relevant if <span class="tt">ttl</span> is set.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md976"></a>
<span class="tt">updateAgeOnHas</span></h2>
<p>When using time-expiring entries with <span class="tt">ttl</span>, setting this to <span class="tt">true</span> will make each item's age reset to 0 whenever its presence in the cache is checked with <span class="tt">has()</span>, causing it to not expire. (It can still fall out of cache based on recency of use, of course.)</p>
<p>This may be overridden by passing an options object to <span class="tt">cache.has()</span>.</p>
<p>Boolean, default false, only relevant if <span class="tt">ttl</span> is set.</p>
<h1 class="doxsection"><a class="anchor" id="autotoc_md977"></a>
API</h1>
<h2 class="doxsection"><a class="anchor" id="autotoc_md978"></a>
<span class="tt">new LRUCache(options)</span></h2>
<p>Create a new LRUCache. All options are documented above, and are on the cache as public members.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md979"></a>
<span class="tt">cache.max</span>, <span class="tt">cache.maxSize</span>, <span class="tt">cache.allowStale</span>,</h2>
<p><span class="tt">cache.noDisposeOnSet</span>, <span class="tt">cache.sizeCalculation</span>, <span class="tt">cache.dispose</span>, <span class="tt">cache.maxSize</span>, <span class="tt">cache.ttl</span>, <span class="tt">cache.updateAgeOnGet</span>, <span class="tt">cache.updateAgeOnHas</span></p>
<p>All option names are exposed as public members on the cache object.</p>
<p>These are intended for read access only. Changing them during program operation can cause undefined behavior.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md980"></a>
<span class="tt">cache.size</span></h2>
<p>The total number of items held in the cache at the current moment.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md981"></a>
<span class="tt">cache.calculatedSize</span></h2>
<p>The total size of items in cache when using size tracking.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md982"></a>
<span class="tt">set(key, value, [{ size, sizeCalculation, ttl, noDisposeOnSet, start, status }])</span></h2>
<p>Add a value to the cache.</p>
<p>Optional options object may contain <span class="tt">ttl</span> and <span class="tt">sizeCalculation</span> as described above, which default to the settings on the cache object.</p>
<p>If <span class="tt">start</span> is provided, then that will set the effective start time for the TTL calculation. Note that this must be a previous value of <span class="tt">performance.now()</span> if supported, or a previous value of <span class="tt">Date.now()</span> if not.</p>
<p>Options object may also include <span class="tt">size</span>, which will prevent calling the <span class="tt">sizeCalculation</span> function and just use the specified number if it is a positive integer, and <span class="tt">noDisposeOnSet</span> which will prevent calling a <span class="tt">dispose</span> function in the case of overwrites.</p>
<p>If the <span class="tt">size</span> (or return value of <span class="tt">sizeCalculation</span>) for a given entry is greater than <span class="tt">maxEntrySize</span>, then the item will not be added to the cache.</p>
<p>Will update the recency of the entry.</p>
<p>Returns the cache object.</p>
<p>For the usage of the <span class="tt">status</span> option, see <b>Status Tracking</b> below.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md983"></a>
<span class="tt">get(key, { updateAgeOnGet, allowStale, status } = {}) =&gt; value</span></h2>
<p>Return a value from the cache.</p>
<p>Will update the recency of the cache entry found.</p>
<p>If the key is not found, <span class="tt">get()</span> will return <span class="tt">undefined</span>. This can be confusing when setting values specifically to <span class="tt">undefined</span>, as in <span class="tt">cache.set(key, undefined)</span>. Use <span class="tt">cache.has()</span> to determine whether a key is present in the cache at all.</p>
<p>For the usage of the <span class="tt">status</span> option, see <b>Status Tracking</b> below.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md984"></a>
<span class="tt">async fetch(key, options = {}) =&gt; Promise</span></h2>
<p>The following options are supported:</p>
<ul>
<li><span class="tt">updateAgeOnGet</span></li>
<li><span class="tt">allowStale</span></li>
<li><span class="tt">size</span></li>
<li><span class="tt">sizeCalculation</span></li>
<li><span class="tt">ttl</span></li>
<li><span class="tt">noDisposeOnSet</span></li>
<li><span class="tt">forceRefresh</span></li>
<li><span class="tt">status</span> - See <b>Status Tracking</b> below.</li>
<li><span class="tt">signal</span> - AbortSignal can be used to cancel the <span class="tt">fetch()</span>. Note that the <span class="tt">signal</span> option provided to the <span class="tt">fetchMethod</span> is a different object, because it must also respond to internal cache state changes, but aborting this signal will abort the one passed to <span class="tt">fetchMethod</span> as well.</li>
<li><span class="tt">fetchContext</span> - sets the <span class="tt">context</span> option passed to the underlying <span class="tt">fetchMethod</span>.</li>
</ul>
<p>If the value is in the cache and not stale, then the returned Promise resolves to the value.</p>
<p>If not in the cache, or beyond its TTL staleness, then <span class="tt">fetchMethod(key, staleValue, { options, signal, context })</span> is called, and the value returned will be added to the cache once resolved.</p>
<p>If called with <span class="tt">allowStale</span>, and an asynchronous fetch is currently in progress to reload a stale value, then the former stale value will be returned.</p>
<p>If called with <span class="tt">forceRefresh</span>, then the cached item will be re-fetched, even if it is not stale. However, if <span class="tt">allowStale</span> is set, then the old value will still be returned. This is useful in cases where you want to force a reload of a cached value. If a background fetch is already in progress, then <span class="tt">forceRefresh</span> has no effect.</p>
<p>Multiple fetches for the same <span class="tt">key</span> will only call <span class="tt">fetchMethod</span> a single time, and all will be resolved when the value is resolved, even if different options are used.</p>
<p>If <span class="tt">fetchMethod</span> is not specified, then this is effectively an alias for <span class="tt">Promise.resolve(cache.get(key))</span>.</p>
<p>When the fetch method resolves to a value, if the fetch has not been aborted due to deletion, eviction, or being overwritten, then it is added to the cache using the options provided.</p>
<p>If the key is evicted or deleted before the <span class="tt">fetchMethod</span> resolves, then the AbortSignal passed to the <span class="tt">fetchMethod</span> will receive an <span class="tt">abort</span> event, and the promise returned by <span class="tt">fetch()</span> will reject with the reason for the abort.</p>
<p>If a <span class="tt">signal</span> is passed to the <span class="tt">fetch()</span> call, then aborting the signal will abort the fetch and cause the <span class="tt">fetch()</span> promise to reject with the reason provided.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md985"></a>
<span class="tt">peek(key, { allowStale } = {}) =&gt; value</span></h2>
<p>Like <span class="tt">get()</span> but doesn't update recency or delete stale items.</p>
<p>Returns <span class="tt">undefined</span> if the item is stale, unless <span class="tt">allowStale</span> is set either on the cache or in the options object.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md986"></a>
<span class="tt">has(key, { updateAgeOnHas, status } = {}) =&gt; Boolean</span></h2>
<p>Check if a key is in the cache, without updating the recency of use. Age is updated if <span class="tt">updateAgeOnHas</span> is set to <span class="tt">true</span> in either the options or the constructor.</p>
<p>Will return <span class="tt">false</span> if the item is stale, even though it is technically in the cache. The difference can be determined (if it matters) by using a <span class="tt">status</span> argument, and inspecting the <span class="tt">has</span> field.</p>
<p>For the usage of the <span class="tt">status</span> option, see <b>Status Tracking</b> below.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md987"></a>
<span class="tt">delete(key)</span></h2>
<p>Deletes a key out of the cache.</p>
<p>Returns <span class="tt">true</span> if the key was deleted, <span class="tt">false</span> otherwise.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md988"></a>
<span class="tt">clear()</span></h2>
<p>Clear the cache entirely, throwing away all values.</p>
<p>Deprecated alias: <span class="tt">reset()</span></p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md989"></a>
<span class="tt">keys()</span></h2>
<p>Return a generator yielding the keys in the cache, in order from most recently used to least recently used.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md990"></a>
<span class="tt">rkeys()</span></h2>
<p>Return a generator yielding the keys in the cache, in order from least recently used to most recently used.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md991"></a>
<span class="tt">values()</span></h2>
<p>Return a generator yielding the values in the cache, in order from most recently used to least recently used.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md992"></a>
<span class="tt">rvalues()</span></h2>
<p>Return a generator yielding the values in the cache, in order from least recently used to most recently used.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md993"></a>
<span class="tt">entries()</span></h2>
<p>Return a generator yielding <span class="tt">[key, value]</span> pairs, in order from most recently used to least recently used.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md994"></a>
<span class="tt">rentries()</span></h2>
<p>Return a generator yielding <span class="tt">[key, value]</span> pairs, in order from least recently used to most recently used.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md995"></a>
<span class="tt">find(fn, [getOptions])</span></h2>
<p>Find a value for which the supplied <span class="tt">fn</span> method returns a truthy value, similar to <span class="tt">Array.find()</span>.</p>
<p><span class="tt">fn</span> is called as <span class="tt">fn(value, key, cache)</span>.</p>
<p>The optional <span class="tt">getOptions</span> are applied to the resulting <span class="tt">get()</span> of the item found.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md996"></a>
<span class="tt">dump()</span></h2>
<p>Return an array of <span class="tt">[key, entry]</span> objects which can be passed to <span class="tt">cache.load()</span></p>
<p>The <span class="tt">start</span> fields are calculated relative to a portable <span class="tt">Date.now()</span> timestamp, even if <span class="tt">performance.now()</span> is available.</p>
<p>Stale entries are always included in the <span class="tt">dump</span>, even if <span class="tt">allowStale</span> is false.</p>
<p>Note: this returns an actual array, not a generator, so it can be more easily passed around.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md997"></a>
<span class="tt">load(entries)</span></h2>
<p>Reset the cache and load in the items in <span class="tt">entries</span> in the order listed. Note that the shape of the resulting cache may be different if the same options are not used in both caches.</p>
<p>The <span class="tt">start</span> fields are assumed to be calculated relative to a portable <span class="tt">Date.now()</span> timestamp, even if <span class="tt">performance.now()</span> is available.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md998"></a>
<span class="tt">purgeStale()</span></h2>
<p>Delete any stale entries. Returns <span class="tt">true</span> if anything was removed, <span class="tt">false</span> otherwise.</p>
<p>Deprecated alias: <span class="tt">prune</span></p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md999"></a>
<span class="tt">getRemainingTTL(key)</span></h2>
<p>Return the number of ms left in the item's TTL. If item is not in cache, returns <span class="tt">0</span>. Returns <span class="tt">Infinity</span> if item is in cache without a defined TTL.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md1000"></a>
<span class="tt">forEach(fn, [thisp])</span></h2>
<p>Call the <span class="tt">fn</span> function with each set of <span class="tt">fn(value, key, cache)</span> in the LRU cache, from most recent to least recently used.</p>
<p>Does not affect recency of use.</p>
<p>If <span class="tt">thisp</span> is provided, function will be called in the <span class="tt">this</span>-context of the provided object.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md1001"></a>
<span class="tt">rforEach(fn, [thisp])</span></h2>
<p>Same as <span class="tt">cache.forEach(fn, thisp)</span>, but in order from least recently used to most recently used.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md1002"></a>
<span class="tt">pop()</span></h2>
<p>Evict the least recently used item, returning its value.</p>
<p>Returns <span class="tt">undefined</span> if cache is empty.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md1003"></a>
Internal Methods and Properties</h2>
<p>In order to optimize performance as much as possible, "private" members and methods are exposed on the object as normal properties, rather than being accessed via Symbols, private members, or closure variables.</p>
<p><b>Do not use or rely on these.</b> They will change or be removed without notice. They will cause undefined behavior if used inappropriately. There is no need or reason to ever call them directly.</p>
<p>This documentation is here so that it is especially clear that this not "undocumented" because someone forgot; it <em>is</em> documented, and the documentation is telling you not to do it.</p>
<p><b>Do not report bugs that stem from using these properties.</b> They will be ignored.</p>
<ul>
<li><span class="tt">initializeTTLTracking()</span> Set up the cache for tracking TTLs</li>
<li><span class="tt">updateItemAge(index)</span> Called when an item age is updated, by internal ID</li>
<li><span class="tt">setItemTTL(index)</span> Called when an item ttl is updated, by internal ID</li>
<li><span class="tt">isStale(index)</span> Called to check an item's staleness, by internal ID</li>
<li><span class="tt">initializeSizeTracking()</span> Set up the cache for tracking item size. Called automatically when a size is specified.</li>
<li><span class="tt">removeItemSize(index)</span> Updates the internal size calculation when an item is removed or modified, by internal ID</li>
<li><span class="tt">addItemSize(index)</span> Updates the internal size calculation when an item is added or modified, by internal ID</li>
<li><span class="tt">indexes()</span> An iterator over the non-stale internal IDs, from most recently to least recently used.</li>
<li><span class="tt">rindexes()</span> An iterator over the non-stale internal IDs, from least recently to most recently used.</li>
<li><span class="tt">newIndex()</span> Create a new internal ID, either reusing a deleted ID, evicting the least recently used ID, or walking to the end of the allotted space.</li>
<li><span class="tt">evict()</span> Evict the least recently used internal ID, returning its ID. Does not do any bounds checking.</li>
<li><span class="tt">connect(p, n)</span> Connect the <span class="tt">p</span> and <span class="tt">n</span> internal IDs in the linked list.</li>
<li><span class="tt">moveToTail(index)</span> Move the specified internal ID to the most recently used position.</li>
<li><span class="tt">keyMap</span> Map of keys to internal IDs</li>
<li><span class="tt">keyList</span> List of keys by internal ID</li>
<li><span class="tt">valList</span> List of values by internal ID</li>
<li><span class="tt">sizes</span> List of calculated sizes by internal ID</li>
<li><span class="tt">ttls</span> List of TTL values by internal ID</li>
<li><span class="tt">starts</span> List of start time values by internal ID</li>
<li><span class="tt">next</span> Array of "next" pointers by internal ID</li>
<li><span class="tt">prev</span> Array of "previous" pointers by internal ID</li>
<li><span class="tt">head</span> Internal ID of least recently used item</li>
<li><span class="tt">tail</span> Internal ID of most recently used item</li>
<li><span class="tt">free</span> Stack of deleted internal IDs</li>
</ul>
<h1 class="doxsection"><a class="anchor" id="autotoc_md1004"></a>
Status Tracking</h1>
<p>Occasionally, it may be useful to track the internal behavior of the cache, particularly for logging, debugging, or for behavior within the <span class="tt">fetchMethod</span>. To do this, you can pass a <span class="tt">status</span> object to the <span class="tt">get()</span>, <span class="tt">set()</span>, <span class="tt">has()</span>, and <span class="tt">fetch()</span> methods.</p>
<p>The <span class="tt">status</span> option should be a plain JavaScript object.</p>
<p>The following fields will be set appropriately:</p>
<div class="fragment"><div class="line">interface Status&lt;V&gt; {</div>
<div class="line">  /**</div>
<div class="line">   * The status of a set() operation.</div>
<div class="line">   *</div>
<div class="line">   * - add: the item was not found in the cache, and was added</div>
<div class="line">   * - update: the item was in the cache, with the same value provided</div>
<div class="line">   * - replace: the item was in the cache, and replaced</div>
<div class="line">   * - miss: the item was not added to the cache for some reason</div>
<div class="line">   */</div>
<div class="line">  set?: &#39;add&#39; | &#39;update&#39; | &#39;replace&#39; | &#39;miss&#39;</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * the ttl stored for the item, or undefined if ttls are not used.</div>
<div class="line">   */</div>
<div class="line">  ttl?: LRUMilliseconds</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * the start time for the item, or undefined if ttls are not used.</div>
<div class="line">   */</div>
<div class="line">  start?: LRUMilliseconds</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * The timestamp used for TTL calculation</div>
<div class="line">   */</div>
<div class="line">  now?: LRUMilliseconds</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * the remaining ttl for the item, or undefined if ttls are not used.</div>
<div class="line">   */</div>
<div class="line">  remainingTTL?: LRUMilliseconds</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * The calculated size for the item, if sizes are used.</div>
<div class="line">   */</div>
<div class="line">  size?: LRUSize</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * A flag indicating that the item was not stored, due to exceeding the</div>
<div class="line">   * {@link maxEntrySize}</div>
<div class="line">   */</div>
<div class="line">  maxEntrySizeExceeded?: true</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * The old value, specified in the case of `set:&#39;update&#39;` or</div>
<div class="line">   * `set:&#39;replace&#39;`</div>
<div class="line">   */</div>
<div class="line">  oldValue?: V</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * The results of a {@link has} operation</div>
<div class="line">   *</div>
<div class="line">   * - hit: the item was found in the cache</div>
<div class="line">   * - stale: the item was found in the cache, but is stale</div>
<div class="line">   * - miss: the item was not found in the cache</div>
<div class="line">   */</div>
<div class="line">  has?: &#39;hit&#39; | &#39;stale&#39; | &#39;miss&#39;</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * The status of a {@link fetch} operation.</div>
<div class="line">   * Note that this can change as the underlying fetch() moves through</div>
<div class="line">   * various states.</div>
<div class="line">   *</div>
<div class="line">   * - inflight: there is another fetch() for this key which is in process</div>
<div class="line">   * - get: there is no fetchMethod, so {@link get} was called.</div>
<div class="line">   * - miss: the item is not in cache, and will be fetched.</div>
<div class="line">   * - hit: the item is in the cache, and was resolved immediately.</div>
<div class="line">   * - stale: the item is in the cache, but stale.</div>
<div class="line">   * - refresh: the item is in the cache, and not stale, but</div>
<div class="line">   *   {@link forceRefresh} was specified.</div>
<div class="line">   */</div>
<div class="line">  fetch?: &#39;get&#39; | &#39;inflight&#39; | &#39;miss&#39; | &#39;hit&#39; | &#39;stale&#39; | &#39;refresh&#39;</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * The {@link fetchMethod} was called</div>
<div class="line">   */</div>
<div class="line">  fetchDispatched?: true</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * The cached value was updated after a successful call to fetchMethod</div>
<div class="line">   */</div>
<div class="line">  fetchUpdated?: true</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * The reason for a fetch() rejection.  Either the error raised by the</div>
<div class="line">   * {@link fetchMethod}, or the reason for an AbortSignal.</div>
<div class="line">   */</div>
<div class="line">  fetchError?: Error</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * The fetch received an abort signal</div>
<div class="line">   */</div>
<div class="line">  fetchAborted?: true</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * The abort signal received was ignored, and the fetch was allowed to</div>
<div class="line">   * continue.</div>
<div class="line">   */</div>
<div class="line">  fetchAbortIgnored?: true</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * The fetchMethod promise resolved successfully</div>
<div class="line">   */</div>
<div class="line">  fetchResolved?: true</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * The results of the fetchMethod promise were stored in the cache</div>
<div class="line">   */</div>
<div class="line">  fetchUpdated?: true</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * The fetchMethod promise was rejected</div>
<div class="line">   */</div>
<div class="line">  fetchRejected?: true</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * The status of a {@link get} operation.</div>
<div class="line">   *</div>
<div class="line">   * - fetching: The item is currently being fetched.  If a previous value is</div>
<div class="line">   *   present and allowed, that will be returned.</div>
<div class="line">   * - stale: The item is in the cache, and is stale.</div>
<div class="line">   * - hit: the item is in the cache</div>
<div class="line">   * - miss: the item is not in the cache</div>
<div class="line">   */</div>
<div class="line">  get?: &#39;stale&#39; | &#39;hit&#39; | &#39;miss&#39;</div>
<div class="line"> </div>
<div class="line">  /**</div>
<div class="line">   * A fetch or get operation returned a stale value.</div>
<div class="line">   */</div>
<div class="line">  returnedStale?: true</div>
<div class="line">}</div>
</div><!-- fragment --><h1 class="doxsection"><a class="anchor" id="autotoc_md1005"></a>
Storage Bounds Safety</h1>
<p>This implementation aims to be as flexible as possible, within the limits of safe memory consumption and optimal performance.</p>
<p>At initial object creation, storage is allocated for <span class="tt">max</span> items. If <span class="tt">max</span> is set to zero, then some performance is lost, and item count is unbounded. Either <span class="tt">maxSize</span> or <span class="tt">ttl</span> <em>must</em> be set if <span class="tt">max</span> is not specified.</p>
<p>If <span class="tt">maxSize</span> is set, then this creates a safe limit on the maximum storage consumed, but without the performance benefits of pre-allocation. When <span class="tt">maxSize</span> is set, every item <em>must</em> provide a size, either via the <span class="tt">sizeCalculation</span> method provided to the constructor, or via a <span class="tt">size</span> or <span class="tt">sizeCalculation</span> option provided to <span class="tt">cache.set()</span>. The size of every item <em>must</em> be a positive integer.</p>
<p>If neither <span class="tt">max</span> nor <span class="tt">maxSize</span> are set, then <span class="tt">ttl</span> tracking must be enabled. Note that, even when tracking item <span class="tt">ttl</span>, items are <em>not</em> preemptively deleted when they become stale, unless <span class="tt">ttlAutopurge</span> is enabled. Instead, they are only purged the next time the key is requested. Thus, if <span class="tt">ttlAutopurge</span>, <span class="tt">max</span>, and <span class="tt">maxSize</span> are all not set, then the cache will potentially grow unbounded.</p>
<p>In this case, a warning is printed to standard error. Future versions may require the use of <span class="tt">ttlAutopurge</span> if <span class="tt">max</span> and <span class="tt">maxSize</span> are not specified.</p>
<p>If you truly wish to use a cache that is bound <em>only</em> by TTL expiration, consider using a <span class="tt">Map</span> object, and calling <span class="tt">setTimeout</span> to delete entries when they expire. It will perform much better than an LRU cache.</p>
<p>Here is an implementation you may use, under the same <a href="./LICENSE">license</a> as this package:</p>
<div class="fragment"><div class="line">// a storage-unbounded ttl cache that is not an lru-cache</div>
<div class="line">const cache = {</div>
<div class="line">  data: new Map(),</div>
<div class="line">  timers: new Map(),</div>
<div class="line">  set: (k, v, ttl) =&gt; {</div>
<div class="line">    if (cache.timers.has(k)) {</div>
<div class="line">      clearTimeout(cache.timers.get(k))</div>
<div class="line">    }</div>
<div class="line">    cache.timers.set(</div>
<div class="line">      k,</div>
<div class="line">      setTimeout(() =&gt; cache.delete(k), ttl)</div>
<div class="line">    )</div>
<div class="line">    cache.data.set(k, v)</div>
<div class="line">  },</div>
<div class="line">  get: k =&gt; cache.data.get(k),</div>
<div class="line">  has: k =&gt; cache.data.has(k),</div>
<div class="line">  delete: k =&gt; {</div>
<div class="line">    if (cache.timers.has(k)) {</div>
<div class="line">      clearTimeout(cache.timers.get(k))</div>
<div class="line">    }</div>
<div class="line">    cache.timers.delete(k)</div>
<div class="line">    return cache.data.delete(k)</div>
<div class="line">  },</div>
<div class="line">  clear: () =&gt; {</div>
<div class="line">    cache.data.clear()</div>
<div class="line">    for (const v of cache.timers.values()) {</div>
<div class="line">      clearTimeout(v)</div>
<div class="line">    }</div>
<div class="line">    cache.timers.clear()</div>
<div class="line">  },</div>
<div class="line">}</div>
</div><!-- fragment --><p>If that isn't to your liking, check out <a href="http://npm.im/@isaacs/ttlcache">@isaacs/ttlcache</a>.</p>
<h1 class="doxsection"><a class="anchor" id="autotoc_md1006"></a>
Performance</h1>
<p>As of January 2022, version 7 of this library is one of the most performant LRU cache implementations in JavaScript.</p>
<p>Benchmarks can be extremely difficult to get right. In particular, the performance of set/get/delete operations on objects will vary <em>wildly</em> depending on the type of key used. V8 is highly optimized for objects with keys that are short strings, especially integer numeric strings. Thus any benchmark which tests <em>solely</em> using numbers as keys will tend to find that an object-based approach performs the best.</p>
<p>Note that coercing <em>anything</em> to strings to use as object keys is unsafe, unless you can be 100% certain that no other type of value will be used. For example:</p>
<div class="fragment"><div class="line">const myCache = {}</div>
<div class="line">const set = (k, v) =&gt; (myCache[k] = v)</div>
<div class="line">const get = k =&gt; myCache[k]</div>
<div class="line"> </div>
<div class="line">set({}, &#39;please hang onto this for me&#39;)</div>
<div class="line">set(&#39;[object Object]&#39;, &#39;oopsie&#39;)</div>
</div><!-- fragment --><p>Also beware of "Just So" stories regarding performance. Garbage collection of large (especially: deep) object graphs can be incredibly costly, with several "tipping points" where it increases exponentially. As a result, putting that off until later can make it much worse, and less predictable. If a library performs well, but only in a scenario where the object graph is kept shallow, then that won't help you if you are using large objects as keys.</p>
<p>In general, when attempting to use a library to improve performance (such as a cache like this one), it's best to choose an option that will perform well in the sorts of scenarios where you'll actually use it.</p>
<p>This library is optimized for repeated gets and minimizing eviction time, since that is the expected need of a LRU. Set operations are somewhat slower on average than a few other options, in part because of that optimization. It is assumed that you'll be caching some costly operation, ideally as rarely as possible, so optimizing set over get would be unwise.</p>
<p>If performance matters to you:</p>
<ol type="1">
<li>If it's at all possible to use small integer values as keys, and you can guarantee that no other types of values will be used as keys, then do that, and use a cache such as <a href="https://npmjs.com/package/lru-fast">lru-fast</a>, or <a href="https://yomguithereal.github.io/mnemonist/lru-cache">mnemonist's LRUCache</a> which uses an Object as its data store.</li>
<li>Failing that, if at all possible, use short non-numeric strings (ie, less than 256 characters) as your keys, and use <a href="https://yomguithereal.github.io/mnemonist/lru-cache">mnemonist's LRUCache</a>.</li>
<li>If the types of your keys will be long strings, strings that look like floats, <span class="tt">null</span>, objects, or some mix of types, or if you aren't sure, then this library will work well for you.</li>
<li>Do not use a <span class="tt">dispose</span> function, size tracking, or especially ttl behavior, unless absolutely needed. These features are convenient, and necessary in some use cases, and every attempt has been made to make the performance impact minimal, but it isn't nothing.</li>
</ol>
<h1 class="doxsection"><a class="anchor" id="autotoc_md1007"></a>
Breaking Changes in Version 7</h1>
<p>This library changed to a different algorithm and internal data structure in version 7, yielding significantly better performance, albeit with some subtle changes as a result.</p>
<p>If you were relying on the internals of LRUCache in version 6 or before, it probably will not work in version 7 and above.</p>
<p>For more info, see the <a class="el" href="nodered_2node__modules_2node-red-dashboard_2_c_h_a_n_g_e_l_o_g_8md.html">change log</a>. </p>
</div><!-- contents -->
</div><!-- doc-content -->
<div id="page-nav" class="page-nav-panel">
<div id="page-nav-resize-handle"></div>
<div id="page-nav-tree">
<div id="page-nav-contents">
</div><!-- page-nav-contents -->
</div><!-- page-nav-tree -->
</div><!-- page-nav -->
</div><!-- container -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a href="dir_27880ab04338f9dc09e25838fc9f82f1.html">serverSide</a></li><li class="navelem"><a href="dir_ea245d1371037254a9bc4ef873bc881e.html">nodered</a></li><li class="navelem"><a href="dir_1fe2c0d618eaa8bd2b6d3d78892e74a8.html">node_modules</a></li><li class="navelem"><a href="dir_05a0747f27b3c00a8b909fc81cc1a3d1.html">lru-cache</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.14.0 </li>
  </ul>
</div>
</body>
</html>
